{
  
    
        "post0": {
            "title": "What is R Markdown",
            "content": "I recently completed a course that used R for various statistical and machine learning methods. In separate articles I discussed the course and my semester project, Text Sentiment Analysis with R, and some R Markdown tips and tricks I learned along the way. . Here I‚Äôll provide a simple introduction to the R Markdown for the uninitiated. I consider this approach, a form of single source publishing, a vital component of reproducible computational research, and an essential skill. . . Not to fret! The basics are straightforward the short time it takes to begin using this method will more than pay for itself. . What is R Markdown? . R Markdown was introduced in 2012 by Yihui Xie, who has authored many of the most important packages in this space, including {knitr}. In his book, R Markdown: The Definitive Guide, Xie describes R Markdown as ‚Äúan authoring framework for data science,‚Äù in which a single .Rmd file is used to ‚Äúsave and execute code, and generate high quality reports‚Äù automatically. A very wide range of document types and formats are supported, including documents and presentations in HTML, PDF, Word, Markdown, Powerpoint, LaTeX, and more. Homework assignments, journal articles, full-length books, formal reports, presentations, web pages, and interactive dashboards are just some of the possibilities described here, with examples of each. To say it is a flexible and dynamic ecosystem is an understatement. . Anyone familiar with R Markdown‚Äôs Python equivalent, Jupyter Notebooks, will find the following familiar. . R Markdown files consist of the following elements: . A metadata header that sets various output options, using the YAML syntax | Body text that is formatted in Markdown | Interspersed code chunks that are set off by three backticks and a curly braced block specifying the language used and setting chunk options | . Rmd also allows users to embed code expressions in the prose by enclosing them in single backticks. . A minimal .Rmd example is included below. This is based on the Xie‚Äôs sample, which I‚Äôve modified to demonstrate all of the elements mentioned above. . title: &quot;Hello R Markdown&quot; author: &quot;Awesome Me&quot; output: html_document This is a paragraph in an _R Markdown_ document. Below is a code chunk: {r fit-plot, echo=TRUE} fit = lm(dist ~ speed, data = cars) b = coef(fit) plot(cars) abline(fit) The slope of the regression is `r round(b[2], digits = 3)`. . Rendering this to HTML via the Preview button results in the following: . . Text is formatted using Markdown, specifically the Pandoc flavor. Xie details the syntax here. . Code output is controlled by options set in each chunk‚Äôs header. .",
            "url": "https://olearydj.github.io/antisimplistic/r/2020/12/08/rmd-intro.html",
            "relUrl": "/r/2020/12/08/rmd-intro.html",
            "date": " ‚Ä¢ Dec 8, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Recent R Learnings",
            "content": "I recently completed a course that used R for various statistical and machine learning methods. In separate articles I discussed the course and my semester project, Text Sentiment Analysis with R, and provided an introduction to R Markdown. . Here I‚Äôll focus on how I used R Studio‚Äôs markdown-based publication tools to integrate my analysis and documentation efforts and render the final results in a variety of formats. . Course Application . Throughout the course I used R Notebooks to combine my prose, code, results, and supporting materials into a single file and render the resulting report directly to PDF. . I started rendering to DOC, which I then converted to PDFs. Spare yourself the pain! Going direct to PDF was as easy as installing TinyTeX. . Tips and Tricks . Keyboard Shortcuts . The keyboard shortcut for inserting an R code chunk is Cmd + Option + I on Mac (Ctrl + Alt + I on Windows). This will insert a new chunk at the cursor position or :boom: split the current chunk! :boom: :astonished: . Converting Between R and R Markdown . Convert your R Markdown file to a standard R file, automatically stripping out the prose and results with knitr::purl(&quot;file.Rmd&quot;, documentation = 1). You can extract just the code, code and chunk headers (the default), or code with text chunks as roxygen comments with documentation parameters of 0, 1, and 2, respectively. . The opposite is also possible using spin to convert R files into R Markdown. Here roxygen comments are used to add markdown (e.g. #&#39; this is *markdown*) or code chunk options (e.g. #+ load-libraries, include=FALSE). For example, given the following R file with a mix of comment styles: . #&#39; ## Initialize #&#39; *Fun* with `mtcars`! #+ summary-stats, echo=FALSE # Summarize mpg summary(mtcars$mpg) . knitr::spin(&quot;spin-me.R&quot;, knit = FALSE) results in the file spin-me.Rmd, with two chunks. The first is markdown with a level 2 header and some bold formatted text. The second is an R code chunk named summary-stats with echo=FALSE that includes a comment: . ## Initialize *Fun* with `mtcars`! {r summary-stats, echo=FALSE} # Summarize mpg summary(mtcars$mpg) . If you are only interested in publishing your R files, simply omit the knit = FALSE parameter from spin to go directly to the final rendered output, e.g. md, pdf, etc. . Twitter . I found several of these on Brendan Cullen‚Äôs recent twitter thread: . #rstats friends: what are your favorite ‚Äúlesser known‚Äù tips &amp; tricks for using R Markdown? e.g. any feature(s) (big or small) you‚Äôve picked up at some point along your #rmarkdown journey that you now use on a regular basis and wish you knew earlier? üëÄüëÇ . &mdash; Brendan Cullen (@_bcullen) December 1, 2020",
            "url": "https://olearydj.github.io/antisimplistic/r/2020/12/08/r-tips-and-tricks.html",
            "relUrl": "/r/2020/12/08/r-tips-and-tricks.html",
            "date": " ‚Ä¢ Dec 8, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Text Sentiment Analysis with R",
            "content": "Introduction . This semester I took INSY 7130 - Data Mining Techniques and Applications for Operations, one of four classes required for the Modeling and Data Analytics for Operations graduate certificate offered by the Department of Industrial and Systems Engineering at Auburn University. I would describe this course as an introductory survey of classic methods. A lot of focus was put on clustering, including hierarchical, k-means, fuzzy k-means, BIRCH, and Kohonen (self-organizing maps) algorithms. Support Vector Machines and Backpropagation Neural Networks were also covered, along with smoothing, time series, and association rules. Most concepts were covered in a single lecture, followed by a second workshop-styled session to demonstrate an R implementation. . The semester project was very open-ended, allowing students to pick a topic of interest and apply suitable methods to explore and make inferences about the data. We were required to us at least one method from the class. I used the following criteria to guide my topic selection process: . Supervised learning using SVM and/or BPNN to meet the project requirement | Something with helpful tidyverse / tidymodels examples that I could use as a framework, allowing this project to also support my self-directed learning | Anything but tabular data! | Something fun and different | . I quickly focused my search on the TidyTuesday project archive and the Animal Crossing: New Horizons exercise, for which Julia Silge documented an excellent solution that I could borrow heavily from. This ticked all the boxes. . TL;DR . The following slides summarize the project and were adapted from a shorter presentation that was given in class. The full report follows for those interested in more detail. . Project . The goal of this project is to perform text sentiment analysis on a data set of user reviews for the Nintendo Switch game Animal Crossing: New Horizons (ACNH), a ‚Äúlife simulation video game developed and published by Nintendo for the Nintendo Switch,‚Äù (Wikipedia). . . From their starting point on a deserted island, ACNH players explore and customize their island, gather and craft items, and catch insects and fish. All of this activity (and much more) plays out in real calendar time as players invest many hours developing their islands into thriving communities of anthropomorphic animals. . In less than 6 months following its March 2020 release, ACNH sold over 22 million units worldwide. It became something of a cultural phenomena in the process, complete with celebrity sightings, grandmothers logging 3,500+ hours of play time, and a thriving in-game currency market based on turnips. . While ACNH provides an interesting, lighthearted context for this project, very little domain knowledge is required, and the problem and methods associated with natural language processing and sentiment analysis are broadly applicable. The roots of this field can be traced back to public opinion analysis in the early 20th century. It wasn‚Äôt until the mid 2000‚Äôs that modern data mining methods made the problem tractable, with 99% of related papers appearing after 2004. Since then, over 7,000 papers have been published on the topic, making it one of the fastest growing research areas in data science (M√§ntyl√§ et al.). . ‚ÄúLiterature Review‚Äù . This project is based on a TidyTuesday exercise. TidyTuesday is a ‚Äúsocial data project in R‚Äù that gives R users of all levels an opportunity to ‚Äúapply [their] R skills, get feedback, explore other‚Äôs work, and connect with the greater #RStats community‚Äù every week. Past data sets have featured everything from Ikea Furniture to Global Crop Yields. . The original TidyTuesday Animal Crossing exercise is linked here. While completing this project I relied on a number of responses to that exercise, including Julia Silge‚Äôs blog post. . The modeling and analysis for this project was performed in R using a workflow based on the tidyverse and tidymodels library collections, employing best practices advocated in those communities. This document was generated directly from the R Markdown file (provided separately), which includes all code. . In addition to the aformentioned blog page, I referred to several other resources created by Ms.¬†Silge and collaborators: . Supervised Machine Learning for Text Analysis in R, an online book authored in R Markdown | Predictive Modeling with Text Using Tidy Data Principles, a tutorial presentation supporting the previous book | Tidy Modeling in R, another online book | Supervised Machine Learning Case Studies in R, a short online course | . Detailed Problem Description . The user_review data provided for this exercise was originally scraped from the popular meta-review site Metacritic. Each of the 2,999 observations has four features: grade, user_name, text, and date. The grade feature is the review score, an integer in the range [0, 10], and text is the written feedback provided by each user. The other fields are self-explanatory. A summary of the data structure is provided below: . ## Rows: 2,999 ## Columns: 4 ## $ grade &lt;dbl&gt; 4, 5, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶ ## $ user_name &lt;chr&gt; &quot;mds27272&quot;, &quot;lolo2178&quot;, &quot;Roachant&quot;, &quot;Houndf&quot;, &quot;Profess‚Ä¶ ## $ text &lt;chr&gt; &quot;My gf started playing before me. No option to create ‚Ä¶ ## $ date &lt;date&gt; 2020-03-20, 2020-03-20, 2020-03-20, 2020-03-20, 2020-‚Ä¶ . My goal is to build a model that can interpret each reviewer‚Äôs sentiment for the game based on the review text. This is a supervised learning problem where grade is used to create a binary label for each review. The underlying assumption is that the score assigned by each user is consistent with the text of their review. The resulting model can be used to categorize user sentiment for unlabled review data. . Development . A full end-to-end analysis follows, including: . Initial data cleaning and exploration | Implement a strategy for model assessment using cross-validation | Build a series of models of increasing complexity | Explore the impact of typical text analysis methods on model accuracy | Rigorously explore the hyperparameter space using grid-based search methods | Select the best model based on appropriate performance metrics | Fit the final model to the full training set &amp; evaluate its performance on test data | . Four different models are built and evaluated in this manner, as described in the Experiments section, below. . Data Prep and Exploration . Before any model is built it is important to explore the data set. I began by creating a histogram to visualize the distribution of user review scores. . . It would be reasonable to expect a gaussian-like distribution here, with a rounded peak somewhere between 3 and 7, tailing off on either side. Instead, we see nearly the opposite, with peaks at 0 and 10, and a shallow u-shaped distribution between. In the world of online reviews, especially for games, this sadly predictable behavior. Here some domain expertise is helpful‚Ä¶ . Review Bombing . Despite ACNH‚Äôs metacritic score of 90% (making it one of the highest rated games of 2020 in the eyes of professional critics), its user reviews average just 55%. Players critical of the limits placed on all but the first player to start the game have resorted to review bombing: . ‚Äúan Internet phenomenon in which large groups of people leave negative user reviews online for a published work, most commonly a video game or a theatrical film, in an attempt to harm the sales or popularity of a product, particularly to draw attention to an issue with the product or its vendor,‚Äù - Wikipedia. . The graph above clearly depicts this adolescent behavior, where the ‚Äúhaters‚Äù and ‚Äúfanboys‚Äù have squared off to show their ire and support, respectively. This is something to keep in mind throughout the project. . Cleaning and Feature Engineering . For the purposes of this project it is also important to have a good sense of what is found in the review text field. Samples of review text were pulled for both positive (grade &gt; 8) and negative (grade &lt; 3) observations and inspected. In doing so I noticed that longer entries tended to include repeated text and end with the word ‚ÄúExpand.‚Äù These problems were likely introduced during the scraping process. I also noticed that some entries are not in English. . After some light initial cleanup of the text field, a new rating column was added to label each review based on the grade. In order to use binary classification methods, rating was set to ‚Äúgood‚Äù for values greater than 5.0 and ‚Äúbad‚Äù otherwise. This cutoff point was chosen based on the average user review of 5.5, but it also seems natural. The remaining cleanup of text data is done as part of the Tokenization process, described below. . Final Exploration . Two final plots were created to complete my exploration. First, the number of words per review was visualized using a histogram. The discontinuity in the resulting graph gives further evidence of problems with the scraped data. Otherwise, this result is as expected, with most reviews being relatively short (less than 75 words), but some users have submitted nearly 1,000 words! The red vertical line shows the average of 120.95 words per review. . Next, I looked for obvious relationships between grade and review length using a box and whiskers plot. The number of outliers increases with more extreme reviews, which seems to follow my intuition that reviewers scoring the game very high or very low are more prone to support their scores with extended rants / raves. . . Train-Test Split . Lastly, the data was split into training and testing sets using the customary 75/25 split. Training data will be used to fit the model and tune the hyperparameters. Test data is reserved for final evaluation of the best model to estimate its performance on new, unseen data. The split was stratified by rating to ensure that the training and test sets were balanced on the response variable. The splits are summarized below. . ## rating count percent source ## 1 bad 1369 60.84 train ## 2 good 881 39.16 train ## 3 bad 456 60.88 test ## 4 good 293 39.12 test . Experiments . Null, Naive Bayes, Support Vector Machine, and Logistic (Lasso) Regression models are built and evaluated on both training and test data. The Null model is used to establish baseline performance metrics. The others were chosen for their performance on sparse data, a key characteristic of natural language problems that results from tokenization of the input data. . Tokenization . Tokenization is the process of converting the input text data into a format suitable for training ML algorithms. While many approaches are used, the method I used covers the essential steps. It begins with splitting the raw strings into tokens based on a combination of whitespace, punctuation, and other factors. I will use word tokens, as is the most common practice, but tokens can be characters, groups of words (n-grams), etc. . The resulting token list is filtered down using a list of stop words to remove elements with little predictive value. The reduced list is then sorted by frequency and the top 500 tokens are converted to ‚Äúterm frequency-inverse document frequency‚Äù, or TFIDF format. According to the documentation, TFIDF is the product of term frequency, the number of times each token appears in each observation, and the inverse document frequency, a measure of how informative a word is based on its rarity). Together these assess the overall value of each token. Finally, the TFIDF values are normalized. . These steps are implemented in the tidymodels::recipe defined below: . review_rec &lt;- recipe(rating ~ text, data = review_train) %&gt;% step_tokenize(text) %&gt;% step_stopwords(text) %&gt;% step_tokenfilter(text, max_tokens = 500) %&gt;% step_tfidf(text) %&gt;% step_normalize(all_predictors()) . This recipe of preprocessing steps will be shared by all model worflows. When applied to the training data, the result is a table with 2,250 rows (one per observation), and 501 columns (one per token, plus the response rating). An extract is shown below for the tokens ‚Äúaccess‚Äù, ‚Äúaccount‚Äù, and ‚Äúaccounts‚Äù. . ## rating tfidf_text_access tfidf_text_account tfidf_text_accounts ## 1 bad -0.1447401 -0.2129978 -0.1330606 . Method 0 - Null Model Baseline . To establish a performance baseline, a Null Model was first constructed. This trivial case predicts the majority class for all observations. Based on the prior stratification statistics, we should expect 60.8% accuracy classifying as bad. . The tidymodels framework was used to define a model specification and workflow (including the Tokenization recipe described above), fit the training data and generate predictions using 10-fold cross-validation, collect the results, and generate the following confusion matrix. . ## Truth ## Prediction bad good ## bad 137 89 ## good 0 0 . As expected, all predictions use the majority class, bad, and the resulting accuracy is 60.8%. Note that only a single fold‚Äôs worth of predictions are included in this result. Using the same model to make predictions for all test data results in the following confusion matrix. . ## Truth ## Prediction bad good ## bad 456 293 ## good 0 0 . Here again the accuracy is 60.9%. The train and test accuracy match in this case because the split was stratified on the response. The Null Model is more accurate than the proverbial coin flip (50%), providing a useful point of comparison for the other models. . Method 1 - Naive Bayes . The first non-trivial model is a Naive Bayes classifier, which uses conditional probabilities to make predictions based on per-class statistics. This method is commonly used for text classification because it is fast, simple, and well-suited to sparse, high-dimensional data. I expect it to perform better than the baseline, but not as well as more sophisticated models to follow. . The same method was used to train the model, generate predictions, and collect metrics. Here we generate a Receiver Operator Characteristics (ROC) curve based on the results of each cross-validation fold. . . This shows the true positive rate (aka recall, aka sensitivity) on the vertical axis vs.¬†the false positive rate (aka (1- text{specificity})). While the end points are pinned at [0, 0] and [1, 1], ideal curves are close to the top left, where true positives are common and false positives are rare. The area under the ROC curve, or ROC-AUC value, is a useful summary statistic. Values of ROC-AUC less than 0.5 perform worse than a random guess, and the max value is 1.0. . The corresponding confusion matrix for a representative cv fold is given below. The average cross-validation accuracy is 74.0%. . ## Truth ## Prediction bad good ## bad 124 48 ## good 13 41 . This is an improvement over the Null Model, but it is clearly better at predicting bad reviews than good ones. When used to generate predictions for all test data, the confusion matrix looks similar. . ## Truth ## Prediction bad good ## bad 418 156 ## good 38 137 . As expected, the Naive Bayes model performs better than the baseline but there is still room for improvement. The test set accuracy of 74.1% suggests that we are not overfitting this model. . Method 2 - Support Vector Machine . The Support Vector Machine model is a significantly more sophisticated method. As discussed in class this semester, SVMs work by finding hyperplanes that optimize class boundaries. A radial basis function (RBF) kernel is used to allow for nonlinearity, where the hyperparameter ( sigma) controls model complexity. . The processed used in this case is the same as above, with one notable addition. A range of values for rbf_sigma are tested using grid_regular() to find the optimal model. This results in 22,500 predictions: 10 cross-validation folds x 10 levels for sigma x 2,250 training observations. Unfortunately, the SVM solver does not return prediction probabilities that are required to build a ROC curve. The plot below shows accuracy, sensitivity, and specificity as a function of ( sigma). . . These curves can be used to select the best value of rbf_sigma for our purposes. The top three models, based on training accuracy, are given below. . # best accuracy for the training data show_best(svm_grid, &quot;accuracy&quot;)[1:3, ] . ## # A tibble: 3 x 7 ## rbf_sigma .metric .estimator mean n std_err .config ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 accuracy binary 0.867 10 0.00650 Preprocessor1_Model10 ## 2 0.0774 accuracy binary 0.606 10 0.0136 Preprocessor1_Model09 ## 3 0.00599 accuracy binary 0.393 10 0.000786 Preprocessor1_Model08 . From this we see that mean accuracy is maximized when ( sigma = 1.0). Honestly, this result seems fishy to me, but I was unable to find fault with the method. Using the optimal parameter value the model was fit using all training data and tthe following predictions were generated for the test set. . ## Truth ## Prediction bad good ## bad 409 47 ## good 47 246 . This looks quite good. Accuracy is 87.4% and the positive and negative predictive value is more balanced. It is easy to see why SVMs are a go-to tool for natural language processing. . Method 3 - Logistic Regression . The fourth and final method uses Logistic Regression with L1 regularization (i.e.¬†lasso) to control model complexity. A range of values are tested for the penalty parameter, adjusting the amount of regularization applied. The resulting ROC curve is plotted below. . . These curves bend closer to the top left corner than the Naive Bayes model, supporting our expectation that this is a better model. As with the SVM model, key metrics are plotted vs the hyperparameter of interest, and the top three models are listed by accuracy. . . ## # A tibble: 3 x 7 ## penalty .metric .estimator mean n std_err .config ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 0.00599 accuracy binary 0.884 10 0.00534 Preprocessor1_Model08 ## 2 0.000464 accuracy binary 0.839 10 0.00800 Preprocessor1_Model07 ## 3 0.0000359 accuracy binary 0.804 10 0.00931 Preprocessor1_Model06 . The top model listed, with accuracy 88.4, has a ROC AUC score of 0.94. Applying the optimal model to the test set yields the following confusion matrix. . ## Truth ## Prediction bad good ## bad 417 52 ## good 39 241 . The final accuracy here is 87.9%, slightly better than what was obtained with the SVM model. . Summarize Analysis . Beginning with the trivial Null Model, the increasing complexity of each subsequent method resulted in improved results. The accuracy on training and test data is summarized below for all models. . ## Model TrnAcc TstAcc ## 1 Null 60.80 60.90 ## 2 NB 74.00 74.10 ## 3 SVM 86.71 87.40 ## 4 LR 88.36 87.90 . With its marginally improved accuracy and reasonably balanced positive / negative predictive power the Logistic Regression model seems the best choice in this exercise. My concerns about the SVM‚Äôs grid search results give me even more confidence in this choice. . Further Exploration . As a final step I adopted the following code from Julia Silge‚Äôs ACNH blog post. It uses the vip package to assess the relative importance of predictor variables. This provides valuable insights into both how the model works and the concepts that drive user sentiment about the game. . . From this we can see that bad reviews are driven by the words ‚Äúgreedy,‚Äù ‚Äúcopies,‚Äù and ‚Äúsecond,‚Äù all of which relate to the outrage over game limitations we discussed before. On the other hand, good reviews focus on the game being ‚Äúgreat,‚Äù ‚Äúbeautiful,‚Äù and ‚Äúcharming,‚Äù among other similarly positive descriptors. . Conclusion . Text sentiment analysis is a valuable tool with many applications. This project gave me a first taste of the process, methods, and tools. It is a deep, fast moving topic that draws from diverse knowledge areas, making it a challenge to master despite the intuitive concepts. . Now that I have a broad understanding, future efforts to more deeply understand best practices for the front-end methods, including preprocessing, feature engineering, stop words, and tokenization, would likely yield the most dramatic improvements. Some specific improvements that I identified during this project include: . Make it multi-class with 3-5 classifications, e.g.¬†good / ok / bad | Improve the quality of the data to minize / eliminate scraping errors | Experiment with different stop word lists, which tend to be domain specific | Experiment with the tokenizing approach, trying n-grams of various length | Use clustering and/or association rules to identify groups of words that relate to user sentiment | Expand the tuning grid parameters, including max_tokens and other preprocessing variables | Try neural net and/or deep neural net models, which are very popular for NLP | . In short, I‚Äôve only scratched the surface of what is possible with this project. It has been a valuable effort and great capstone to the class. . References . M√§ntyl√§, Mika V., et al. ‚ÄúThe Evolution of Sentiment Analysis‚ÄîA Review of Research Topics, Venues, and Top Cited Papers.‚Äù Computer Science Review, vol. 27, Feb. 2018, pp. 16‚Äì32, doi:10.1016/j.cosrev.2017.10.002. | Silge, Julia. Supervised Machine Learning Case Studies in R! ¬∑ A Free Interactive Course. https://supervised-ml-course.netlify.app/. Accessed 21 Oct. 2020. | ‚Äî. Supervised Machine Learning for Text Analysis in R. https://smltar.com/. Accessed 21 Oct. 2020. | ‚Äî. Tidy Modeling with R. https://www.tmwr.org/. Accessed 21 Oct. 2020. | Silge, Julia, and Emil Hvitfeldt. Predictive Modeling with Text Using Tidy Data Principles. https://emilhvitfeldt.github.io/useR2020-text-modeling-tutorial/. Accessed 2 Dec. 2020. |",
            "url": "https://olearydj.github.io/antisimplistic/r/portfolio/2020/12/07/acnh-reviews-project.html",
            "relUrl": "/r/portfolio/2020/12/07/acnh-reviews-project.html",
            "date": " ‚Ä¢ Dec 7, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Exploring Jupyter Notebook-Based Research",
            "content": "Much of my life has been centered around software. In middle school I was writing vertical blank interrupts in assembly language for the 6502 in my Atari 800. In 1994 I co-founded the first of two software development companies that I‚Äôve run ever since. Despite all that, I‚Äôve never considered myself a ‚Äúsoftware guy.‚Äù The traditional pattern of write code, compile, check is‚Ä¶ well, hard. And discouraging. I have tremendous respect for folks that have mastered this, and consider myself very fortunate to have employed many great, and a few truly exceptional software engineers. . But for me, there had to be a better way. Upon returning to graduate school for Dan 2.0, I found it. Python and Jupyter Notebooks (JNs). The combination of Python‚Äôs interpreted nature and the way that JNs combine code, output, and text provided an approach that was much more natural and welcoming to me. Over time, it allowed me to build enough skill and confidence ‚Äúhacking away‚Äù at data science projects to begin exploring software engineering and carpentry. . To that end, I‚Äôve recently spent a lot of time reading about workflows built around notebooks, especially those that facilitate good software engineering practices, single-source publishing, integration, and deployment. Below I‚Äôve shared some of the most insightful links I encountered in that search, along with short summaries and relevant background information. As my PhD focus transitions from classes to research, my goal is to leverage some of these methods to improve the efficiency, quality, and reproducibility of my work while making it easier to publish in a variety of ways. . nbdev: use Jupyter Notebooks for everything: this article first opened my eyes to very interesting things going on in the JN ecosystem, leading to many of the articles linked below. nbdev is a ‚Äúhighly opinionated‚Äù Python programming environment that supports software engineering best practices (automated documentation, package creation, testing, continuous integration, source control, and more) for JNs. nbdev was created by the team that created the deep learning PyTorch front-end fastai and the JN-based blogging tool fastpages, which this page is built with. Not at all coincidentally, fastpages is powered, at least in part, by nbdev. All of this was developed by the article‚Äôs author Jeremy Howard, former President and Chief Data Scientist of Kaggle, and Sylvain Gugger, now at Hugging Face. Together, they co-authored Deep Learning for Coders with Fastai and PyTorch: AI Applications Without a PhD. I am working with nbdev and will share my experience in future updates. | How to use Jupyter Notebooks in 2020: the first of an insightful three-part series on the JN ecosystem. In it, author Lj Miranda covers the evolution of methods of practice in the data science landscape, current tools and best practices for notebook-based development workflows, and thoughts on the future. I found the second part particularly useful, with lots of technical detail. | Beyond Interactive: Notebook Innovation at Netflix: continuing with the JN theme, this article discusses how ‚Äúnotebooks are the most popular tool for working with data‚Äù at Netflix. It describes the workflow, including scheduled runs of parameterized notebooks and collecting code and output into notebooks to create a record of various jobs. It also describes the extensive infrastructure required to support this at scale. At the time of its writing in 2018, the authors were planning to run more than 150,000 notebook-based jobs per day. This is the first of a two-part series. The second, Scheduling Notebooks at Netflix, dives more deeply into the details. Note that two of the original authors, Matthew Seal and Michelle Ufford have since left Netflix to found noteable.io, a ‚ÄúSaaS offering for integrated Jupyter Notebooks.‚Äù | How to share Jupyter Notebooks: complements the previous article by providing more ways to share JNs including gist, nbviewer, and binder. By Andrea Zonca | Presenting Code Using Jupyter Notebook Slides: I was today years old when I learned that the ability to run slide-based presentations was built into JNs! A very short tutorial on how to do it by Matthew Speck. | . My focus above is on Jupyter Notebooks, but there are lots of cool things going on in the RStudio world as well, especially related single-source, ‚Äúone-click‚Äù publishing. Many great web-books about/using R have been published from R Notebooks using R markdown and bookdown, including Hadley Wickham‚Äôs classic R for Data Science. A list of other examples can be found on the bookdown archive page. . Here are a few relevant and timely R-related links: . RStudio 1.4 Preview: Citations: a close look at the deep support for citations included in the upcoming RStudio v1.4, currently available as a preview release. Other features in the update include improved support for Python and a visual markdown editor. | Single-source publishing for R users: describes a typical process for generating html- and pdf-based books from R Markdown using bookdown and ways to simplify and automate the process. I don‚Äôt pretend to understand everything going on here, but know enough to appreciate the author, Ma√´lle Salmon‚Äôs work enough to share and bookmark it! | .",
            "url": "https://olearydj.github.io/antisimplistic/worthreading/jupyter/2020/11/19/wr-exploring-jn-based-research.html",
            "relUrl": "/worthreading/jupyter/2020/11/19/wr-exploring-jn-based-research.html",
            "date": " ‚Ä¢ Nov 19, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Worth Reading, November 16, 2020",
            "content": "This first installment is unusually long as I wanted to include material going back a few weeks. . Web Articles . How to improve software engineering skills as a researcher: another excellent article by Lj Miranda, which provides a roadmap of skills that begins with version control and culminates in the deployment of a ML service. This is presented in the context of introducing those in academics / research to software engineering fundamentals. It is not a tutorial, but provides a number of such links for each step in the journey, many of which I will likely share in future editions of Worth Reading. | Balanced Accuracy: What and Why?: Jo Etzel discusses the challenges with interpreting overall classification accuracy (the proportion of examples correctly classified) when the training set is imbalanced, and suggests that balanced accuracy (the average of the proportion corrects of each class individually) may be more useful in those situations. See also the papers related to balanced accuracy, below. | The AI Hierarchy of Needs: summons Maslow to make the point that good data science built on a hierarchy of methods (house of cards?) starting with collection, and moving through storing, exploring, and labeling, before arriving at learning. The success at each level depends on the quality of work in those before. Written by Monica Rogati, former VP of Data at Jawbone and Senior Data Scientist at LinkedIn. | Data Science Archetypes: part of the Navigating a Data Science Career unit in Brandon Rohrer‚Äôs End-to-End Machine Learning online course. In it, Brandon identifies 6 archetypes of people in data science (generalist, detective, oracle, maker, unicorn, and diva) based on their mix of skills in analysis, modeling, engineering, and mechanics. I included this useful perspective in my recent talk on AI, ML, and Data Science Concepts for the Data Science Society of Auburn. | Making Peace with Personal Branding: valuable tips from Rachel Thomas covering various ways to build a personal brand, including blogging, twitter, and public speaking. Rachel is the co-founder of fastai, which I talk a lot about in the first item on this list. I‚Äôve really enjoyed everything I‚Äôve read by her, including this interview on Hacker Noon. | Could web-based development (game) engines be the end of App Stores?: a quick summary of the history of the app store leading up to recent controversy concerning Apple‚Äôs app store policies and pricing, including their very public legal battle with Epic Games. Also discusses the ‚Äúrise of the game engines,‚Äù and the movement towards web-based tools in this space, including the author, Alan Smithson‚Äôs, own MetaVRse Engine. Particularly timely given this morning‚Äôs announcement from Apple that, starting January 1, 2021, they are cutting app store fees by 50% (to 15%) for developers / businesses earning less than $1m/yr. | . Online Education / Tutorials . Supervised Machine Learning Case Studies in R: an excellent overview of and introduction to supervised learning the tidyverse / tidymodels way by Julia Silge. Formerly a Data Scientist at Stack Overflow, Julia is now a Software Engineer at RStudio where she maintains tidymodels. A mix of slides and simple interactive code exercises that walk you through 4 different small but comprehensive case studies. | Intro to tidymodels with nflfastR: this slide show from Tom Mock, Customer Success Representative in the high tech and sports vertical at RStudio, is a nice follow-on to his colleague‚Äôs work on the previous item. Covers an end-to-end case study of tidymodel methods using NFL data in a 90 minute workshop format. Tom also runs the popular #TidyTuesday R project community. | Exponential Smoothing: a great summary of basic smoothing and time series methods, cleanly implemented with modern R methods. This page is part of what appears to be an excellent resource provided by the University of Cincinnati, the UC Business Analytics R Programming guide, originally developed by Bradley Boehmke. | . Papers . Experimenting with Automatic Video Creation from a Web Page: an interesting summary of a paper from Google Research. As the title suggests, they have developed a method to automatically convert static web pages into short marketing videos, given duration and aspect ratio. | Data Organization in Spreadsheets: provides sensible recommendations for structuring, filling out, and using spreadsheets for storing and organizing data. Written by Karl Browman and Kara Woo | PMLB: A Large Benchmark Suite for Machine Learning Evaluation and Comparison: ‚Äúintroduces the Penn Machine Learning Benchmark (PMLB), a publicly available dataset initialized with 165 real-world, simulated, and toy benchmark datasets for evaluating supervised classification methods.‚Äù A Python interface is provided to facilitate loading and preprocessing the data. A wide range of scikit-learn classifiers were evaluated to assess performance. | .",
            "url": "https://olearydj.github.io/antisimplistic/worthreading/2020/11/16/readings.html",
            "relUrl": "/worthreading/2020/11/16/readings.html",
            "date": " ‚Ä¢ Nov 16, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Big Picture Data Science Concepts",
            "content": "In less than 4 months, with minimal fanfare, the Data Science Society of Auburn has attracted nearly 100 members, including a mix of graduate and undergraduate students pursuing a wide range of degrees. Upon hearing about this new student organization I reached out to the founder, Jordan Eckert, to offer my assistance. I have since been elected as the Director of Career Programming. If you are reading this and are interested in presenting to our students and/or participating in an upcoming career event, I welcome your email at dan.oleary@auburn.edu! . Today I presented a talk intended to help students understand the ‚Äúbig picture‚Äù of Data Science and connect it to study / career opportunities. It was inspired during a lecture on neural networks, when a classmate asked ‚Äòhow is this related to AI?‚Äô Most classes are so busy with the details that they fail to explain the big picture. I hope this helps close that gap. . View / Downloaded on GitHub. .",
            "url": "https://olearydj.github.io/antisimplistic/presentation/datascience/2020/11/16/dssa-aiml-concepts.html",
            "relUrl": "/presentation/datascience/2020/11/16/dssa-aiml-concepts.html",
            "date": " ‚Ä¢ Nov 16, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "BET 3520 Fall 2020 Course Summary",
            "content": "For the last two years I‚Äôve supported first-year courses in Auburn‚Äôs Business-Engineering-Technology (BET) minor as a teaching assistant and occasional lecturer. This Fall I was given the opportunity to take over those courses as the instructor of record. 26 lectures, 850+ new slides, and more assignments / grading than I‚Äôd like to think about later, my inaugural semester for BET 3520 and 3560 is all but over. . To celebrate I thought I‚Äôd share the following deck, a version of which was used to do the final exam review for 3520. It condenses over 400 slides worth of material, spanning more than 22 hours of traditional lectures (delivered via zoom, of course, #COVID), into about 70 slides that highlight about 30% of the semester‚Äôs total content. . View / Downloaded on GitHub .",
            "url": "https://olearydj.github.io/antisimplistic/teaching/presentation/2020/11/13/bet3520-fall2020.html",
            "relUrl": "/teaching/presentation/2020/11/13/bet3520-fall2020.html",
            "date": " ‚Ä¢ Nov 13, 2020"
        }
        
    
  
    
  
    
        ,"post8": {
            "title": "Blogging with Fastpages",
            "content": "I may be a hypocrite, but I‚Äôm not wrong‚Ä¶ . I‚Äôve spent over 25 years preaching the value of a portfolio site to artists, software engineers, and designers that wanted to join my studio or learn how to get into games or related industries. Now that I‚Äôm 6 months into my PhD and planning for career 2.0, it‚Äôs past time for me to do the same. This sums up the justification in a single tweet: . The popularity of this tweet makes me laugh, because it&#39;s an illustrative example! I thought about trying to get a screenshot of David&#39;s slide, but just took a terrible phone photo of a webinar and tweeted with the quote. . &mdash; Amelia McNamara (@AmeliaMN) July 22, 2018 I recently finished reading Build a Career in Data Science1, which I recommend. It motivated me to start the process of sharing my work. . Introduction to Fastpages . This site is built with fastpages, a platform for building static Jekyll web blogs from Jupyter Notebooks (JNs). Markdown and Word DOCs are also supported. . . From their github page: . fastpages automates the process of creating blog posts via GitHub Actions, so you don‚Äôt have to fuss with conversion scripts. A full list of features can be found on GitHub. . Fastpages is built by the team that created the deep learning PyTorch front-end fastai and the Python programming environment nbdev. The team is led by Jeremy Howard, former President and Chief Data Scientist of Kaggle and author of Deep Learning for Coders with Fastai and PyTorch: AI Applications Without a PhD2. . I was first introduced fastpages and nbdev during the recent ACM TechTalk, It‚Äôs Time Deep Learning Learned from Software Engineering, presented by Howard and moderated by his collaborator Hamel Husain. . From Introducing Fastpages: . fastpages uses nbdev to power the conversion process of Jupyter Notebooks to blog posts. When you save a notebook into the /_notebooks folder of your repository, GitHub Actions applies nbdev against those notebooks automatically. The same process occurs when you save Word documents or markdown files into the _word or _posts directory, respectively. . Some resources I found helpful in launching this blog: . The fastpages github page has detailed setup instructions | This video tutorial created by Abdul Majed walks you through the initial setup process | A sample jupyter-based blog page provides a live demonstration of its capabilities | . I was able to get the initial site live quite quickly with little drama, and have found the process of modifying existing content and publishing new material straightforward so far. Before choosing fastpages I considered the following hosting / authoring options: . A general purpose site like Wix | A page on Medium or Substack | Other JN-based tools like Pelican | Finding a way to use JNs in blogdown3 | . I decided that Fastpages was the best way for me to publish JN-based work directly, with professional look and feel, on a site that I control, for free. That‚Äôs a pretty great combination. I also like that it supports Markdown (like this page), is part of the larger fast.ai family of products (and philosophy), and is hosted on github. . Finally, if you still need to be convinced of the value of building a portfolio, and what to include in one give the following resources a look: . Advice to aspiring data scientists: start a blog on David Robinson‚Äôs Variance Explained | Data Science Portfolios That Will Get You the Job | Thinking of blogging about Data Science? Here are some tips and possible benefits. | . Many of us need to spend less time consuming, and more time creating. Now you know how and why, so go publish something! . . Robinson, Emily, and Jacqueline Nolis. Build a Career in Data Science. Simon and Schuster, 2020.¬†&#8617; . | Howard, Jeremy, and Sylvain Gugger. Deep Learning for Coders with Fastai and PyTorch. O‚ÄôReilly Media, Inc., 2020.¬†&#8617; . | There is a lot of cool stuff going on in R these days and blogdown supports a lot of interesting publishing workflows, but I ultimately decided that it would probably be easier to find a way to publish my R work using fastpages than to publish my Python work with blogdown. Time will tell‚Ä¶¬†&#8617; . |",
            "url": "https://olearydj.github.io/antisimplistic/publication/jupyter/2020/11/06/starting-fastpages.html",
            "relUrl": "/publication/jupyter/2020/11/06/starting-fastpages.html",
            "date": " ‚Ä¢ Nov 6, 2020"
        }
        
    
  
    
  
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": ". Links . Blog / Portfolio | LinkedIn | Twitter | Github | SlideShare | Resume (Long Form) | Student CV | . Bio . . Antisimplistic is Dan O‚ÄôLeary, a second career PhD student and Graduate Assistant in the Department of Industrial and Systems Engineering at Auburn University. After 23 years in the games industry as a co-founder of the independent development studio n-Space, it was past time for a change. . I currently teach undergraduate courses covering innovation, entrepreneurship, product development and leadership in the department‚Äôs Business-Engingeering-Technology minor, and support related initiatives at the Thomas Walter Center for Technology Management. . My academic and research interests are broad, encompassing data science, simulation, and visualization. For my dissertation I plan to apply methods from those areas to improve our understanding of processes related to innovation or product development processes. . Meanwhile, I continue to maintain GUNSTRUCTION, which I founded in 2012. This year (2020) it will log over 90 million user interactions across web, iOS, and Android devices. .",
          "url": "https://olearydj.github.io/antisimplistic/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://olearydj.github.io/antisimplistic/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}